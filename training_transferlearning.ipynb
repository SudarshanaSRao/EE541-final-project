{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt8vtPRtEhMw"
      },
      "source": [
        "### Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY45UPJuEhM3",
        "outputId": "3a8dde43-d02c-454f-ad75-6ce939992239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2022.9.24)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "%pip install opendatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPSn_wX3EhM5"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2SUAgSf3EhM5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import opendatasets as od\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Subset\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils import ProgressBar, plot_metrics\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q2zFt90EhM6"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYvBiGTzEhM6",
        "outputId": "789dd3cd-cb16-47be-8480-00dbcc2db868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: christopherconroy\n",
            "Your Kaggle Key: ··········\n",
            "Downloading asl-alphabet.zip to ./asl-alphabet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.03G/1.03G [00:04<00:00, 271MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download Kaggle dataset (Kaggle username and key is required)\n",
        "# {\"username\":\"christopherconroy\",\"key\":\"1915e76943ae798bc236fb7c2de6d28d\"}\n",
        "od.download('https://www.kaggle.com/datasets/grassknoted/asl-alphabet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DtjxxNkEEhM7"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "TEST_DATA_DIR = 'asl-alphabet/asl_alphabet_test/asl_alphabet_test'\n",
        "TRAIN_DATA_DIR = 'asl-alphabet/asl_alphabet_train/asl_alphabet_train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDgjOcVmEhM8",
        "outputId": "0843fcd3-cfb8-48ff-c374-8c5b942a86d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Initialize dataset\n",
        "dataset = torchvision.datasets.ImageFolder(root = TRAIN_DATA_DIR, transform = ToTensor())\n",
        "num_inputs = np.array(dataset[0][0].numpy().shape).prod()\n",
        "num_outputs = len(dataset.classes)\n",
        "\n",
        "# Check for CUDA GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f_ISSRVcEhM-"
      },
      "outputs": [],
      "source": [
        "def split_dataset(dataset, num_samples, train_split, batch_size, seed = 0):\n",
        "    '''\n",
        "    Create training and test data loaders from the given dataset.\n",
        "\n",
        "    Params:\n",
        "        dataset = PyTorch Dataset instance for full dataset\n",
        "        num_samples = Number of samples to use from the full dataset\n",
        "        train_split = Fraction of train data in train/test split\n",
        "        batch_size Minibatch size for training\n",
        "        seed = Random seed for dataset shuffle and split. Set to None for no seed.\n",
        "\n",
        "    Returns:\n",
        "        train_loader = Dataloader for the training samples\n",
        "        test_loader = Dataloader for the test samples\n",
        "    '''\n",
        "\n",
        "    # Perform stratified split of dataset indicies\n",
        "    train_size = int((num_samples * train_split) // batch_size) * batch_size\n",
        "    test_size = num_samples - train_size\n",
        "    dataset_inds = list(range(len(dataset)))\n",
        "    train_inds, test_inds = train_test_split(dataset_inds, train_size = train_size, test_size = test_size, random_state = seed, stratify = dataset.targets)\n",
        "\n",
        "    # Create training and test subsets\n",
        "    train_set = Subset(dataset, train_inds)\n",
        "    test_set = Subset(dataset, test_inds)\n",
        "\n",
        "    # Initialize data loader\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mNkxR2AEhM_"
      },
      "source": [
        "### Training Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uKxvcsnlEhNA"
      },
      "outputs": [],
      "source": [
        "def train(data_loader, model, loss_func, optimizer):\n",
        "    # Initialize parameters\n",
        "    size = len(data_loader.dataset)\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Set mode to training\n",
        "    model.train()\n",
        "\n",
        "    # Initialize progress bar\n",
        "    progress = ProgressBar('Train Progress', len(data_loader))\n",
        "\n",
        "    # Iterate through batches\n",
        "    for images, labels in data_loader: \n",
        "        # Transfer images and labels to GPU\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        #images = images.view(-1, num_inputs)\n",
        "        \n",
        "        # Forward pass \n",
        "        outputs = model(images)\n",
        "        loss = loss_func(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimization\n",
        "        optimizer.step()\n",
        "\n",
        "        # Transfer outputs and labels to CPU\n",
        "        outputs, labels = outputs.cpu(), labels.cpu()\n",
        "        \n",
        "        # Compute batch metrics\n",
        "        total_loss += loss.item()\n",
        "        pred = torch.max(outputs, 1)[1]\n",
        "        correct += (pred == labels).sum().numpy()\n",
        "\n",
        "        # Update progress\n",
        "        progress.step()\n",
        "\n",
        "    # Compute metrics for dataset\n",
        "    total_loss /= num_batches\n",
        "    accuracy = (correct / size) * 100\n",
        "\n",
        "    return total_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-8pfhoEzEhNB"
      },
      "outputs": [],
      "source": [
        "def test(data_loader, model, loss_func):\n",
        "    # Initialize parameters\n",
        "    size = len(data_loader.dataset)\n",
        "    num_batches = len(data_loader)\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Set mode to evaluation\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize progress bar\n",
        "    progress = ProgressBar('Valid Progress', len(data_loader))\n",
        "\n",
        "    # Iterate through batches\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            # Transfer images and labels to GPU\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            #images = images.view(-1, num_inputs)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = loss_func(outputs, labels)\n",
        "\n",
        "            # Transfer outputs and labels to CPU\n",
        "            outputs, labels = outputs.cpu(), labels.cpu()\n",
        "\n",
        "            # Compute batch metrics\n",
        "            total_loss += loss.item()\n",
        "            pred = torch.max(outputs, 1)[1]\n",
        "            correct += (pred == labels).sum().numpy()\n",
        "\n",
        "            # Update progress\n",
        "            progress.step()\n",
        "            \n",
        "    # Compute metrics for dataset\n",
        "    total_loss /= num_batches\n",
        "    accuracy = (correct / size) * 100\n",
        "\n",
        "    return total_loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TIBp-4gdEhNC"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, valid_loader, learning_rate, num_epochs, weight_decay = 0):\n",
        "    # Initialize training parameters\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
        "\n",
        "    # Initialize metrics\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "    train_accuracy_list = []\n",
        "    test_accuracy_list = []\n",
        "\n",
        "    # Train model\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train and evaluate model\n",
        "        train_loss, train_accuracy = train(train_loader, model, loss_func, optimizer)\n",
        "        valid_loss, valid_accuracy = test(valid_loader, model, loss_func)\n",
        "\n",
        "        # Store epoch metrics\n",
        "        train_loss_list.append(train_loss)\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        test_loss_list.append(valid_loss)\n",
        "        test_accuracy_list.append(valid_accuracy)\n",
        "\n",
        "        # Output progress\n",
        "        print('Epoch {} | Loss = {:.4f} | Train Accuracy = {:.2f}% | Test Accuracy = {:.2f}%'.format(epoch + 1, train_loss, train_accuracy, valid_accuracy))\n",
        "\n",
        "    return (train_loss_list, train_accuracy_list), (test_loss_list, test_accuracy_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR6C5dyTEhND"
      },
      "source": [
        "### Model #1 - MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztjN9Ov-EhND",
        "outputId": "0513ab41-c51c-4a33-fab5-257de6ca9063"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net1(\n",
              "  (hidden1): Linear(in_features=120000, out_features=1000, bias=True)\n",
              "  (output): Linear(in_features=1000, out_features=29, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "class Net1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.hidden1 = nn.Linear(num_inputs, 1000)\n",
        "        self.output = nn.Linear(1000, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.output(x)\n",
        "        return x\n",
        "\n",
        "model1 = Net1()\n",
        "model1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "PTJusiyWEhNE",
        "outputId": "78173e26-2ae9-4a50-e5a6-18dbf7aed260"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ef4326b0bed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_loader1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_metrics1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_metrics1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgooglenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-a9c73576a040>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, valid_loader, learning_rate, num_epochs, weight_decay)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Train and evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-f6379ce1f136>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, loss_func, optimizer)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-4ff701b25a11>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (600x200 and 120000x1000)"
          ]
        }
      ],
      "source": [
        "train_loader1, valid_loader1 = split_dataset(dataset, 200, 0.8, 1)\n",
        "train_metrics1, valid_metrics1 = train_model(model1, train_loader1, valid_loader1, 0.001, 50)\n",
        "googlenet = models.googlenet(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsUhQgL-EhNE"
      },
      "outputs": [],
      "source": [
        "plot_metrics(train_metrics1, valid_metrics1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "959ea64129db48a8ec807348f5586b619e10ab98f5ce73f35da71fb5d22946c2"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}